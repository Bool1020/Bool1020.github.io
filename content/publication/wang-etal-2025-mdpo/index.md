---
title: 'MDPO: Customized Direct Preference Optimization with a Metric-based Sampler
  for Question and Answer Generation'
authors:
- admin
- Bowen Tian
- Yueyang Su
- Yixing Fan
- Jiafeng Guo
date: '2025-01-01'
publishDate: '2025-01-21T07:25:24.736457Z'
publication_types:
- paper-conference
publication: '*Proceedings of the 31st International Conference on Computational Linguistics* (COLING 2025)'
abstract: With the extensive use of large language models, automatically generating
  QA datasets for domain-specific fine-tuning has become crucial. However, considering
  the multifaceted demands for readability, diversity, and comprehensiveness of QA
  data, current methodologies fall short in producing high-quality QA datasets. Moreover,
  the dependence of existing evaluation metrics on ground truth labels further exacerbates
  the challenges associated with the selection of QA data. In this paper, we introduce
  a novel method for QA data generation, denoted as MDPO. We proposes a set of unsupervised
  evaluation metrics for QA data, enabling multidimensional assessment based on the
  relationships among context,question and answer. Furthermore, leveraging these metrics,
  we implement a customized direct preference optimization process that guides large
  language models to produce high-quality and domain-specific QA pairs. Empirical
  results on public datasets indicate that MDPO`s performance substantially surpasses
  that of state-of-the-art methods.
links:
- name: URL
  url: https://aclanthology.org/2025.coling-main.711/
---
